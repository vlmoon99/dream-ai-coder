{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algo of project generation\n",
    "\n",
    "#1.\n",
    "\n",
    "#2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4all import GPT4All\n",
    "\n",
    "list_gpus = GPT4All.list_gpus()\n",
    "list_gpus = [gpu for gpu in list_gpus if \"cuda:\" in gpu]\n",
    "\n",
    "list_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\",device=list_gpus[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model.chat_session(\n",
    "    system_prompt= \"\",\n",
    "    prompt_template= \"\"\n",
    "):\n",
    "    print(model.generate(\"quadratic formula\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.generate(\"quadratic formula\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are the code writer using Flutter/Dart and only usng internal pacakges\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write me simple list item page example\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=2048,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are the code writer using Flutter/Dart and only usng internal pacakges\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write me simple ai asistant (which help peopels with ibs) busines logic using clear Flutter/Dart \"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=2048,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "dart_code = \"\"\"\n",
    "1. Filename: user.dart\n",
    "import 'package:json_annotation/json_annotation.dart';\n",
    "\n",
    "part 'user.g.dart';\n",
    "\n",
    "@JsonSerializable()\n",
    "class User {\n",
    "    final int id;\n",
    "    final String name;\n",
    "    final String email;\n",
    "\n",
    "    User({\n",
    "        required this.id,\n",
    "        required this.name,\n",
    "        required this.email,\n",
    "    });\n",
    "\n",
    "    factory User.fromJson(Map<String, dynamic> json) => _$UserFromJson(json);\n",
    "\n",
    "    Map<String, dynamic> toJson() => _$UserToJson(this);\n",
    "}\n",
    "2. Filename: product.dart\n",
    "import 'package:json_annotation/json_annotation.dart';\n",
    "\n",
    "part 'product.g.dart';\n",
    "\n",
    "@JsonSerializable()\n",
    "class Product {\n",
    "    final int id;\n",
    "    final String name;\n",
    "    final double price;\n",
    "\n",
    "    Product({\n",
    "        required this.id,\n",
    "        required this.name,\n",
    "        required this.price,\n",
    "    });\n",
    "\n",
    "    factory Product.fromJson(Map<String, dynamic> json) => _$ProductFromJson(json);\n",
    "\n",
    "    Map<String, dynamic> toJson() => _$ProductToJson(this);\n",
    "}\n",
    "3. Filename: order.dart\n",
    "import 'package:json_annotation/json_annotation.dart';\n",
    "\n",
    "part 'order.g.dart';\n",
    "\n",
    "@JsonSerializable()\n",
    "class Order {\n",
    "    final int id;\n",
    "    final int userId;\n",
    "    final List<int> productIds;\n",
    "\n",
    "    Order({\n",
    "        required this.id,\n",
    "        required this.userId,\n",
    "        required this.productIds,\n",
    "    });\n",
    "\n",
    "    factory Order.fromJson(Map<String, dynamic> json) => _$OrderFromJson(json);\n",
    "\n",
    "    Map<String, dynamic> toJson() => _$OrderToJson(this);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Regular expression to extract filenames and their respective code\n",
    "pattern = r\"(\\d+\\.\\sFilename:\\s(.*?)\\n(.*?))(?=\\d+\\. Filename:|\\Z)\"\n",
    "\n",
    "matches = re.finditer(pattern, dart_code, re.DOTALL)\n",
    "\n",
    "# Parse the data into a list of tuples (filename, code)\n",
    "parsed_models = [(match.group(2).strip(), match.group(3).strip()) for match in matches]\n",
    "\n",
    "# Print the parsed models\n",
    "for filename, code in parsed_models:\n",
    "    print(f\"Filename: {filename}\\nCode:\\n{code}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4all import GPT4All\n",
    "\n",
    "class AIGenerationService:\n",
    "    def __init__(self):\n",
    "        list_gpus = GPT4All.list_gpus()\n",
    "        list_gpus = [gpu for gpu in list_gpus if \"cuda:\" in gpu]\n",
    "        self.computer_devices = list_gpus\n",
    "        self.llm_model = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\",device=list_gpus[0]) \n",
    "        print(\"Create AIGenerationService\")\n",
    "\n",
    "    def generateCode(self,system_prompt : str,prompt_template : str, busines_requirements : str):\n",
    "        with self.llm_model.chat_session(system_prompt=system_prompt,prompt_template = prompt_template):\n",
    "            generarted_content = self.llm_model.generate(busines_requirements, max_tokens=2048)\n",
    "            print(generarted_content)\n",
    "\n",
    "    def executeCommand(self):\n",
    "        print(\"executeCommand\")\n",
    "\n",
    "\n",
    "\n",
    "ai_generation_service = AIGenerationService()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw text template for generating Dart models and application files\n",
    "prompt_template = r\"\"\"\n",
    "Generate Dart code based on the following business requirements.\n",
    "\n",
    "Output the results strictly in JSON format with each JSON object on a new line:\n",
    "\n",
    "Each JSON object should include:\n",
    "- filename: The name of the Dart file (e.g., user.dart)\n",
    "- filename_code: The code for the corresponding file\n",
    "\n",
    "Do not include any additional explanations or text.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "system_prompt = r\"\"\"\n",
    "You are a code-generator that creates Dart models and a simple main application file for a blog post application. Your task is to generate code based on the given business requirements and output the results in JSON format.\n",
    "\n",
    "For each model, output the following JSON structure:\n",
    "\n",
    "{\n",
    "    \"filename\": \"example.dart\",\n",
    "    \"filename_code\": \"import 'package:json_annotation/json_annotation.dart'; ...\",\n",
    "}\n",
    "\n",
    "Follow this format to ensure that each file and its corresponding code are clearly structured and easily identifiable.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ai_generation_service.generateCode(\n",
    "    prompt_template=prompt_template,\n",
    "    system_prompt=system_prompt,\n",
    "    busines_requirements=\"Create the Blog post app, wherein users will perform CRUD operations on posts and display them on the main screen, it must be a simple concept app without any complex logic\"\n",
    ")\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
